{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Requenamar3/DeepLearning/blob/main/Whisper_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_FJPk1VYHI6"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/18-05-41.m4a\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MR-1K6i__IR",
        "outputId": "4413dedd-63bd-407d-a03c-8135eb0c5b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:11<00:00, 43.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:02.000]  Give me insurance information!\n",
            "[00:02.000 --> 00:09.000]  You could also use an NLU to handle the understanding and use an LLM to generate the intense content.\n",
            "[00:09.000 --> 00:13.000]  For example, you might have an ordering assistant at a burger restaurant\n",
            "[00:13.000 --> 00:18.000]  and the user asks for a bucket of chicken but your burger restaurant doesn't sell a bucket of chicken\n",
            "[00:18.000 --> 00:24.000]  because your intent triggers a prompt with the menu showcasing everything the restaurant sells\n",
            "[00:24.000 --> 00:26.000]  rather than a decision tree of canned responses.\n",
            "[00:26.000 --> 00:29.000]  You can inform the user that you don't sell buckets of chicken\n",
            "[00:29.000 --> 00:32.000]  but you could offer, say, a fried chicken sandwich instead.\n",
            "[00:32.000 --> 00:37.000]  And doing something like this reduces the chance of hallucinations considerably\n",
            "[00:37.000 --> 00:41.000]  because people will only see this response if they hit that intent.\n",
            "[00:41.000 --> 00:43.000]  If you start using this hybrid approach,\n",
            "[00:43.000 --> 00:48.000]  I think building assistance becomes less about focusing on each word and turn of the conversation\n",
            "[00:48.000 --> 00:51.000]  and more around creating scaffolding that holds your agent up.\n",
            "[00:51.000 --> 00:56.000]  This way we can start to build agents that are flexible among them to move and respond\n",
            "[00:56.000 --> 00:59.000]  with the customer and not the other way round.\n",
            "[01:02.000 --> 01:05.000]  You could also use an NLU to handle the understanding\n",
            "[01:05.000 --> 01:09.000]  and use an LLM to generate the intense content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMG2Cqd-dGRf"
      },
      "outputs": [],
      "source": [
        "!whisper \"/content/18-05-41.m4a\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E19kzRnYb22i"
      },
      "outputs": [],
      "source": [
        "!whisper \"/content/18-09-05.m4a\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgMC2az0pU8T"
      },
      "outputs": [],
      "source": [
        "!whisper \"/content/15-04-44.m4a\" --language English"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}